# -*- coding: utf-8 -*-
"""imdb movies.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/184dekY_euDhz0OOB8siZJ_PX9Hg4oa8V
"""

import pandas as pd
import re
movies = pd.read_csv('imdb_movies.csv',encoding='latin-1')
movies.columns =['text','label']
movies['text'] =movies['text'].map(lambda x : re.sub(r'\d+',"",x))
movies['text'] =movies['text'].map(lambda x: re.sub(r'[\([{})\]]',"",x))
movies.head()

X =movies['text']
y =movies['label']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.2,random_state=1)

from sklearn.feature_extraction.text import TfidfVectorizer
transformer =TfidfVectorizer(stop_words ='english',max_features =5000)
X_train =transformer.fit_transform(X_train).toarray()
X_test =transformer.transform(X_test).toarray()

X_train.shape

from sklearn.ensemble  import RandomForestClassifier
model =RandomForestClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

from bs4 import BeautifulSoup
import requests
url ='https://sportall.ge/fekhburthi/fekhburthii/legionerebi/174649-ra-ushlis-saqarthvelos-nakrebs-khels-ufro-didi-miznebisken-sad-varth-obieqturad.html?orderBy=0&all=1&add_new=0&reply=0#comments'
content =requests.get(url).text
content =BeautifulSoup(content,'html.parser')

comments =content.find_all("div",class_ ="c_comment")
print(comments)

# for comment in comments:
#   print(comment.text.strip())

from deep_translator import GoogleTranslator
translator =GoogleTranslator(source='auto',target ='en')

for comment in comments:
  english_version =translator.translate(comment.text)
  label =model.predict(transformer.transform([english_version]))[0]
  print(label)

movies.loc[0,'text']